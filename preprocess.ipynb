{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement unsupervised_absa (from versions: none)\n",
      "ERROR: No matching distribution found for unsupervised_absa\n"
     ]
    }
   ],
   "source": [
    "%pip install unsupervised_absa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Diagram\n",
    "2. Explaination of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "In this section, any dataset can be used. Including dataset that doesn't have any aspect terms or categories, and dataset that doesn't have polarity. For this example, we will used an existing dataset for aspect based sentiment analysis called semeval2014 task 4 which include aspect terms and categories analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: sem_eval2014_task4_raw/All\n",
      "Found cached dataset sem_eval2014_task4_raw (C:/Users/User/.cache/huggingface/datasets/Yaxin___sem_eval2014_task4_raw/All/0.0.1/3f2b4b42aa35876b7faba99ae6f73b106955b8c9162c6fc5160fd74497f7790f)\n",
      "No config specified, defaulting to: sem_eval2014_task4_raw/All\n",
      "Found cached dataset sem_eval2014_task4_raw (C:/Users/User/.cache/huggingface/datasets/Yaxin___sem_eval2014_task4_raw/All/0.0.1/3f2b4b42aa35876b7faba99ae6f73b106955b8c9162c6fc5160fd74497f7790f)\n",
      "No config specified, defaulting to: sem_eval2014_task4_raw/All\n",
      "Found cached dataset sem_eval2014_task4_raw (C:/Users/User/.cache/huggingface/datasets/Yaxin___sem_eval2014_task4_raw/All/0.0.1/3f2b4b42aa35876b7faba99ae6f73b106955b8c9162c6fc5160fd74497f7790f)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from huggingface\n",
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset(\"Yaxin/SemEval2014Task4Raw\", split='train')\n",
    "validation_dataset = load_dataset(\"Yaxin/SemEval2014Task4Raw\", split='validation')\n",
    "test_dataset = load_dataset(\"Yaxin/SemEval2014Task4Raw\", split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset doesn't have any polarity but it does have terms and categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next will be preprocessing the data. In this sample, most of the text dataset are pretty cleaned. But for the sake of this demo, we will clean it anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsupervised_absa.preprocess import simple_preprocessing\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing strip_spaces: 100%|██████████| 11/11 [00:00<00:00, 24.73it/s]         \n"
     ]
    }
   ],
   "source": [
    "# preprocessing currently only supports pandas.series, list, and numpy\n",
    "train_df = train_dataset.to_pandas()\n",
    "train_df['text'] = simple_preprocessing(train_df['text'])\n",
    "train_df = train_df.drop_duplicates(subset=['text'])\n",
    "preprocessed_dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'aspectTerms', 'aspectCategories', 'domain', 'sentenceId', '__index_level_0__'],\n",
       "    num_rows: 6055\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processes in the preprocessing pipeline include:\n",
    "1. encode decode\n",
    "2. convert_unicode\n",
    "3. remove_url\n",
    "4. remove_control_characters\n",
    "5. remove_tags\n",
    "6. remove_emoji\n",
    "7. convert_contractions\n",
    "8. remove_numbers\n",
    "9. remove_punctuation\n",
    "10. remove_multiple_spaces\n",
    "11. strip_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248ebce3fd854ff99b08dcb6328204fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6055 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessed_dataset.save_to_disk('data/preprocessed_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
