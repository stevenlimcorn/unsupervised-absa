{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.mnli import MnliPipeline\n",
    "model = MnliPipeline('microsoft/deberta-large-mnli')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data_2015/pos tag/laptop_pos_tag.json') as f:\n",
    "    pos_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos_tag_df = pd.DataFrame.from_dict(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1735it [00:00, 19261.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# expanding the df to sentence to 1 pos tag df\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "new_df = {'text': [], 'sid': [], 'aspectLabel': [], 'term ground truth': [], 'category ground truth': []}\n",
    "for index, row in tqdm(pos_tag_df.iterrows()):\n",
    "    if len(row['pos_tag']) != 0:\n",
    "        text = row['text']\n",
    "        sid = row['sentenceId']\n",
    "        term_ground_truth = row['term ground truth']\n",
    "        category_ground_truth = row['term ground truth']\n",
    "        for aspect in row['pos_tag']:\n",
    "            new_df['aspectLabel'].append(aspect['word'])\n",
    "            new_df['text'].append(text)\n",
    "            new_df['sid'].append(sid)\n",
    "            new_df['term ground truth'].append(term_ground_truth)\n",
    "            new_df['category ground truth'].append(category_ground_truth)\n",
    "\n",
    "mnli_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-23 20:14:27.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mPreprocessing dataset with length: 3972\u001b[0m\n",
      "\u001b[32m2023-04-23 20:14:27.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mExtracting polarity with model: microsoft/deberta-large-mnli\u001b[0m\n",
      "100%|██████████| 3972/3972 [47:03<00:00,  1.41it/s] \n",
      "\u001b[32m2023-04-23 21:01:30.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mPostprocessing outputs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = model.extract_polarity(mnli_df, 'text', 'aspectLabel', device='cuda', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc54b42ce8324d03a201d1ff6aac1dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk('../data_2015/mnli/laptop_aspect_term')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words Count > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data_2015/pos tag/laptop_pos_tag_low_counts.json') as f:\n",
    "    pos_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos_tag_df = pd.DataFrame.from_dict(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1735it [00:00, 18639.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# expanding the df to sentence to 1 pos tag df\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "new_df = {'text': [], 'sid': [], 'aspectLabel': [], 'term ground truth': [], 'category ground truth': []}\n",
    "for index, row in tqdm(pos_tag_df.iterrows()):\n",
    "    if len(row['pos_tag']) != 0:\n",
    "        text = row['text']\n",
    "        sid = row['sentenceId']\n",
    "        term_ground_truth = row['term ground truth']\n",
    "        category_ground_truth = row['term ground truth']\n",
    "        for aspect in row['pos_tag']:\n",
    "            new_df['aspectLabel'].append(aspect['word'])\n",
    "            new_df['text'].append(text)\n",
    "            new_df['sid'].append(sid)\n",
    "            new_df['term ground truth'].append(term_ground_truth)\n",
    "            new_df['category ground truth'].append(category_ground_truth)\n",
    "\n",
    "mnli_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-23 21:01:31.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mPreprocessing dataset with length: 3060\u001b[0m\n",
      "\u001b[32m2023-04-23 21:01:31.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mExtracting polarity with model: microsoft/deberta-large-mnli\u001b[0m\n",
      "100%|██████████| 3060/3060 [35:51<00:00,  1.42it/s] \n",
      "\u001b[32m2023-04-23 21:37:23.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mPostprocessing outputs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "low_counts_dataset = model.extract_polarity(mnli_df, 'text', 'aspectLabel', device='cuda', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5a3aa37d5c4adf94fe0800a2723451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3060 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "low_counts_dataset.save_to_disk('../data_2015/mnli/laptop_aspect_term_low_counts')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data_2015/pos tag/restaurant_pos_tag.json') as f:\n",
    "    pos_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos_tag_df = pd.DataFrame.from_dict(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1311it [00:00, 11962.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# expanding the df to sentence to 1 pos tag df\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "new_df = {'text': [], 'sid': [], 'aspectLabel': [], 'term ground truth': [], 'category ground truth': []}\n",
    "for index, row in tqdm(pos_tag_df.iterrows()):\n",
    "    if len(row['pos_tag']) != 0:\n",
    "        text = row['text']\n",
    "        sid = row['sentenceId']\n",
    "        term_ground_truth = row['term ground truth']\n",
    "        category_ground_truth = row['term ground truth']\n",
    "        for aspect in row['pos_tag']:\n",
    "            new_df['aspectLabel'].append(aspect['word'])\n",
    "            new_df['text'].append(text)\n",
    "            new_df['sid'].append(sid)\n",
    "            new_df['term ground truth'].append(term_ground_truth)\n",
    "            new_df['category ground truth'].append(category_ground_truth)\n",
    "\n",
    "mnli_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-23 21:37:24.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mPreprocessing dataset with length: 2755\u001b[0m\n",
      "\u001b[32m2023-04-23 21:37:24.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mExtracting polarity with model: microsoft/deberta-large-mnli\u001b[0m\n",
      "100%|██████████| 2755/2755 [30:23<00:00,  1.51it/s]\n",
      "\u001b[32m2023-04-23 22:07:47.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mPostprocessing outputs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = model.extract_polarity(mnli_df, 'text', 'aspectLabel', device='cuda', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae734cbfa174cd8bdb5e1a0b43636e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2755 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk('../data_2015/mnli/restaurant_aspect_term')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words Count > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data_2015/pos tag/restaurant_pos_tag_low_counts.json') as f:\n",
    "    pos_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos_tag_df = pd.DataFrame.from_dict(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1311it [00:00, 14717.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# expanding the df to sentence to 1 pos tag df\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "new_df = {'text': [], 'sid': [], 'aspectLabel': [], 'term ground truth': [], 'category ground truth': []}\n",
    "for index, row in tqdm(pos_tag_df.iterrows()):\n",
    "    if len(row['pos_tag']) != 0:\n",
    "        text = row['text']\n",
    "        sid = row['sentenceId']\n",
    "        term_ground_truth = row['term ground truth']\n",
    "        category_ground_truth = row['term ground truth']\n",
    "        for aspect in row['pos_tag']:\n",
    "            new_df['aspectLabel'].append(aspect['word'])\n",
    "            new_df['text'].append(text)\n",
    "            new_df['sid'].append(sid)\n",
    "            new_df['term ground truth'].append(term_ground_truth)\n",
    "            new_df['category ground truth'].append(category_ground_truth)\n",
    "\n",
    "mnli_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-23 22:07:48.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mPreprocessing dataset with length: 2047\u001b[0m\n",
      "\u001b[32m2023-04-23 22:07:48.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mExtracting polarity with model: microsoft/deberta-large-mnli\u001b[0m\n",
      "100%|██████████| 2047/2047 [22:58<00:00,  1.48it/s]\n",
      "\u001b[32m2023-04-23 22:30:47.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mPostprocessing outputs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "low_counts_dataset = model.extract_polarity(mnli_df, 'text', 'aspectLabel', device='cuda', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e33488686974352865149c17391bcf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2047 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "low_counts_dataset.save_to_disk('../data_2015/mnli/restaurant_aspect_term_low_counts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
