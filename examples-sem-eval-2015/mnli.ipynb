{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing unsupervised_absa.egg-info\\PKG-INFO\n",
      "writing dependency_links to unsupervised_absa.egg-info\\dependency_links.txt\n",
      "writing top-level names to unsupervised_absa.egg-info\\top_level.txt\n",
      "reading manifest file 'unsupervised_absa.egg-info\\SOURCES.txt'\n",
      "writing manifest file 'unsupervised_absa.egg-info\\SOURCES.txt'\n",
      "installing library code to build\\bdist.win-amd64\\egg\n",
      "running install_lib\n",
      "running build_py\n",
      "copying unsupervised_absa\\embedding.py -> build\\lib\\unsupervised_absa\n",
      "copying unsupervised_absa\\mnli.py -> build\\lib\\unsupervised_absa\n",
      "creating build\\bdist.win-amd64\\egg\n",
      "creating build\\bdist.win-amd64\\egg\\unsupervised_absa\n",
      "copying build\\lib\\unsupervised_absa\\clustering.py -> build\\bdist.win-amd64\\egg\\unsupervised_absa\n",
      "copying build\\lib\\unsupervised_absa\\embedding.py -> build\\bdist.win-amd64\\egg\\unsupervised_absa\n",
      "copying build\\lib\\unsupervised_absa\\eval.py -> build\\bdist.win-amd64\\egg\\unsupervised_absa\n",
      "copying build\\lib\\unsupervised_absa\\mnli.py -> build\\bdist.win-amd64\\egg\\unsupervised_absa\n",
      "copying build\\lib\\unsupervised_absa\\myfunctions.py -> build\\bdist.win-amd64\\egg\\unsupervised_absa\n",
      "copying build\\lib\\unsupervised_absa\\preprocess.py -> build\\bdist.win-amd64\\egg\\unsupervised_absa\n",
      "copying build\\lib\\unsupervised_absa\\tagger.py -> build\\bdist.win-amd64\\egg\\unsupervised_absa\n",
      "copying build\\lib\\unsupervised_absa\\__init__.py -> build\\bdist.win-amd64\\egg\\unsupervised_absa\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\unsupervised_absa\\clustering.py to clustering.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\unsupervised_absa\\embedding.py to embedding.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\unsupervised_absa\\eval.py to eval.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\unsupervised_absa\\mnli.py to mnli.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\unsupervised_absa\\myfunctions.py to myfunctions.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\unsupervised_absa\\preprocess.py to preprocess.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\unsupervised_absa\\tagger.py to tagger.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\unsupervised_absa\\__init__.py to __init__.cpython-310.pyc\n",
      "creating build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying unsupervised_absa.egg-info\\PKG-INFO -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying unsupervised_absa.egg-info\\SOURCES.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying unsupervised_absa.egg-info\\dependency_links.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying unsupervised_absa.egg-info\\top_level.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "creating 'dist\\unsupervised_absa-0.1.0-py3.10.egg' and adding 'build\\bdist.win-amd64\\egg' to it\n",
      "removing 'build\\bdist.win-amd64\\egg' (and everything under it)\n",
      "Processing unsupervised_absa-0.1.0-py3.10.egg\n",
      "Removing c:\\users\\user\\anaconda3\\envs\\torch-flair\\lib\\site-packages\\unsupervised_absa-0.1.0-py3.10.egg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\torch-flair\\lib\\site-packages\\setuptools\\installer.py:27: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\envs\\torch-flair\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\envs\\torch-flair\\lib\\site-packages\\setuptools\\command\\easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "error: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\users\\\\user\\\\anaconda3\\\\envs\\\\torch-flair\\\\lib\\\\site-packages\\\\unsupervised_absa-0.1.0-py3.10.egg'\n"
     ]
    }
   ],
   "source": [
    "!cd .. & python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.mnli import MnliPipeline\n",
    "model = MnliPipeline('microsoft/deberta-large-mnli')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data_2015/pos tag/laptop_pos_tag.json') as f:\n",
    "    pos_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos_tag_df = pd.DataFrame.from_dict(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1735it [00:00, 16748.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# expanding the df to sentence to 1 pos tag df\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "new_df = {'text': [], 'sid': [], 'aspectLabel': [], 'term ground truth': [], 'category ground truth': []}\n",
    "for index, row in tqdm(pos_tag_df.iterrows()):\n",
    "    if len(row['pos_tag']) != 0:\n",
    "        text = row['text']\n",
    "        sid = row['sentenceId']\n",
    "        term_ground_truth = row['term ground truth']\n",
    "        category_ground_truth = row['term ground truth']\n",
    "        for aspect in row['pos_tag']:\n",
    "            new_df['aspectLabel'].append(aspect['word'])\n",
    "            new_df['text'].append(text)\n",
    "            new_df['sid'].append(sid)\n",
    "            new_df['term ground truth'].append(term_ground_truth)\n",
    "            new_df['category ground truth'].append(category_ground_truth)\n",
    "\n",
    "mnli_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-24 20:18:53.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mPreprocessing dataset with length: 5\u001b[0m\n",
      "\u001b[32m2023-04-24 20:18:53.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mExtracting polarity with model: microsoft/deberta-large-mnli\u001b[0m\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
      "\u001b[32m2023-04-24 20:18:58.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mPostprocessing outputs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = model.extract_polarity(mnli_df[:5], 'text', 'aspectLabel', device='cuda', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['positive', 'negative', 'neutral', 'polarity', 'term', 'text'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc54b42ce8324d03a201d1ff6aac1dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk('../data_2015/mnli/laptop_aspect_term')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words Count > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data_2015/pos tag/laptop_pos_tag_low_counts.json') as f:\n",
    "    pos_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos_tag_df = pd.DataFrame.from_dict(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1735it [00:00, 18639.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# expanding the df to sentence to 1 pos tag df\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "new_df = {'text': [], 'sid': [], 'aspectLabel': [], 'term ground truth': [], 'category ground truth': []}\n",
    "for index, row in tqdm(pos_tag_df.iterrows()):\n",
    "    if len(row['pos_tag']) != 0:\n",
    "        text = row['text']\n",
    "        sid = row['sentenceId']\n",
    "        term_ground_truth = row['term ground truth']\n",
    "        category_ground_truth = row['term ground truth']\n",
    "        for aspect in row['pos_tag']:\n",
    "            new_df['aspectLabel'].append(aspect['word'])\n",
    "            new_df['text'].append(text)\n",
    "            new_df['sid'].append(sid)\n",
    "            new_df['term ground truth'].append(term_ground_truth)\n",
    "            new_df['category ground truth'].append(category_ground_truth)\n",
    "\n",
    "mnli_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-23 21:01:31.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mPreprocessing dataset with length: 3060\u001b[0m\n",
      "\u001b[32m2023-04-23 21:01:31.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mExtracting polarity with model: microsoft/deberta-large-mnli\u001b[0m\n",
      "100%|██████████| 3060/3060 [35:51<00:00,  1.42it/s] \n",
      "\u001b[32m2023-04-23 21:37:23.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mPostprocessing outputs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "low_counts_dataset = model.extract_polarity(mnli_df, 'text', 'aspectLabel', device='cuda', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5a3aa37d5c4adf94fe0800a2723451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3060 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "low_counts_dataset.save_to_disk('../data_2015/mnli/laptop_aspect_term_low_counts')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data_2015/pos tag/restaurant_pos_tag.json') as f:\n",
    "    pos_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos_tag_df = pd.DataFrame.from_dict(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1311it [00:00, 11962.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# expanding the df to sentence to 1 pos tag df\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "new_df = {'text': [], 'sid': [], 'aspectLabel': [], 'term ground truth': [], 'category ground truth': []}\n",
    "for index, row in tqdm(pos_tag_df.iterrows()):\n",
    "    if len(row['pos_tag']) != 0:\n",
    "        text = row['text']\n",
    "        sid = row['sentenceId']\n",
    "        term_ground_truth = row['term ground truth']\n",
    "        category_ground_truth = row['term ground truth']\n",
    "        for aspect in row['pos_tag']:\n",
    "            new_df['aspectLabel'].append(aspect['word'])\n",
    "            new_df['text'].append(text)\n",
    "            new_df['sid'].append(sid)\n",
    "            new_df['term ground truth'].append(term_ground_truth)\n",
    "            new_df['category ground truth'].append(category_ground_truth)\n",
    "\n",
    "mnli_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-23 21:37:24.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mPreprocessing dataset with length: 2755\u001b[0m\n",
      "\u001b[32m2023-04-23 21:37:24.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mExtracting polarity with model: microsoft/deberta-large-mnli\u001b[0m\n",
      "100%|██████████| 2755/2755 [30:23<00:00,  1.51it/s]\n",
      "\u001b[32m2023-04-23 22:07:47.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mPostprocessing outputs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = model.extract_polarity(mnli_df, 'text', 'aspectLabel', device='cuda', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae734cbfa174cd8bdb5e1a0b43636e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2755 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk('../data_2015/mnli/restaurant_aspect_term')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words Count > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data_2015/pos tag/restaurant_pos_tag_low_counts.json') as f:\n",
    "    pos_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos_tag_df = pd.DataFrame.from_dict(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1311it [00:00, 14717.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# expanding the df to sentence to 1 pos tag df\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "new_df = {'text': [], 'sid': [], 'aspectLabel': [], 'term ground truth': [], 'category ground truth': []}\n",
    "for index, row in tqdm(pos_tag_df.iterrows()):\n",
    "    if len(row['pos_tag']) != 0:\n",
    "        text = row['text']\n",
    "        sid = row['sentenceId']\n",
    "        term_ground_truth = row['term ground truth']\n",
    "        category_ground_truth = row['term ground truth']\n",
    "        for aspect in row['pos_tag']:\n",
    "            new_df['aspectLabel'].append(aspect['word'])\n",
    "            new_df['text'].append(text)\n",
    "            new_df['sid'].append(sid)\n",
    "            new_df['term ground truth'].append(term_ground_truth)\n",
    "            new_df['category ground truth'].append(category_ground_truth)\n",
    "\n",
    "mnli_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-23 22:07:48.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mPreprocessing dataset with length: 2047\u001b[0m\n",
      "\u001b[32m2023-04-23 22:07:48.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mExtracting polarity with model: microsoft/deberta-large-mnli\u001b[0m\n",
      "100%|██████████| 2047/2047 [22:58<00:00,  1.48it/s]\n",
      "\u001b[32m2023-04-23 22:30:47.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mPostprocessing outputs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "low_counts_dataset = model.extract_polarity(mnli_df, 'text', 'aspectLabel', device='cuda', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e33488686974352865149c17391bcf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2047 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "low_counts_dataset.save_to_disk('../data_2015/mnli/restaurant_aspect_term_low_counts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
