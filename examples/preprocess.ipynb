{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Diagram\n",
    "2. Explaination of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "In this section, any dataset can be used. Including dataset that doesn't have any aspect terms or categories, and dataset that doesn't have polarity. For this example, we will used an existing dataset for aspect based sentiment analysis called semeval2014 task 4 which include aspect terms and categories analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/absa/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No config specified, defaulting to: sem_eval2014_task4_raw/All\n",
      "Found cached dataset sem_eval2014_task4_raw (/Users/stevenlimcorn/.cache/huggingface/datasets/Yaxin___sem_eval2014_task4_raw/All/0.0.1/3f2b4b42aa35876b7faba99ae6f73b106955b8c9162c6fc5160fd74497f7790f)\n",
      "No config specified, defaulting to: sem_eval2014_task4_raw/All\n",
      "Found cached dataset sem_eval2014_task4_raw (/Users/stevenlimcorn/.cache/huggingface/datasets/Yaxin___sem_eval2014_task4_raw/All/0.0.1/3f2b4b42aa35876b7faba99ae6f73b106955b8c9162c6fc5160fd74497f7790f)\n",
      "No config specified, defaulting to: sem_eval2014_task4_raw/All\n",
      "Found cached dataset sem_eval2014_task4_raw (/Users/stevenlimcorn/.cache/huggingface/datasets/Yaxin___sem_eval2014_task4_raw/All/0.0.1/3f2b4b42aa35876b7faba99ae6f73b106955b8c9162c6fc5160fd74497f7790f)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from huggingface\n",
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset(\"Yaxin/SemEval2014Task4Raw\", split='train')\n",
    "validation_dataset = load_dataset(\"Yaxin/SemEval2014Task4Raw\", split='validation')\n",
    "test_dataset = load_dataset(\"Yaxin/SemEval2014Task4Raw\", split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Where Gabriela personaly greets you and recommends you what to eat.',\n",
       " 'aspectTerms': [],\n",
       " 'aspectCategories': [{'category': 'service', 'polarity': 'positive'}],\n",
       " 'domain': 'restaurants',\n",
       " 'sentenceId': '2534'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset doesn't have any polarity but it does have terms and categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next will be preprocessing the data. In this sample, most of the text dataset are pretty cleaned. But for the sake of this demo, we will clean it anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsupervised_absa.preprocess import simple_preprocessing\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing strip_spaces: 100%|██████████| 11/11 [00:00<00:00, 33.20it/s]         \n"
     ]
    }
   ],
   "source": [
    "# preprocessing currently only supports pandas.series, list, and numpy\n",
    "train_df = train_dataset.to_pandas()\n",
    "train_df['text'] = simple_preprocessing(train_df['text'])\n",
    "train_df = train_df.drop_duplicates(subset=['text']).set_index('sentenceId')\n",
    "preprocessed_dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'aspectTerms', 'aspectCategories', 'domain', 'sentenceId'],\n",
       "    num_rows: 6055\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processes in the preprocessing pipeline include:\n",
    "1. encode decode\n",
    "2. convert_unicode\n",
    "3. remove_url\n",
    "4. remove_control_characters\n",
    "5. remove_tags\n",
    "6. remove_emoji\n",
    "7. convert_contractions\n",
    "8. remove_numbers\n",
    "9. remove_punctuation\n",
    "10. remove_multiple_spaces\n",
    "11. strip_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e589a5201b314f1f9341d9780cb4c52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6055 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessed_dataset.save_to_disk('data/preprocessed_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
