{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Word Embedding Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import gensim\n",
    "preprocessed_dataset = load_from_disk('../data/preprocessed_data')\n",
    "preprocessed_df = preprocessed_dataset.to_pandas()\n",
    "preprocessed_df = preprocessed_df.drop_duplicates(subset=['text'])\n",
    "laptop_df = preprocessed_df[preprocessed_df['domain'] == 'laptops']\n",
    "restaurant_df = preprocessed_df[preprocessed_df['domain'] == 'restaurants']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_data = list(preprocessed_df['text'].apply(gensim.utils.simple_preprocess))\n",
    "gensim_laptop = list(laptop_df['text'].apply(gensim.utils.simple_preprocess))\n",
    "gensim_restaurant = list(restaurant_df['text'].apply(gensim.utils.simple_preprocess))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "from gensim.models import KeyedVectors\n",
    "model_path = gensim.downloader.load('word2vec-google-news-300', return_path=True)\n",
    "print(model_path)\n",
    "# load the model to keyedvector and save it as keyedvector\n",
    "vectors = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on all semeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=2,\n",
    "    min_count=5,\n",
    "#     sample=6e-5, \n",
    "    alpha=0.03, \n",
    "    min_alpha=0.0007, \n",
    "    workers=cores-1,\n",
    "    epochs=50\n",
    ")\n",
    "model.build_vocab(gensim_data, progress_per=10)\n",
    "total_examples = model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab([list(vectors.key_to_index.keys())], update=True)\n",
    "# train on your data\n",
    "model.train(gensim_data, total_examples=total_examples, epochs=model.epochs)\n",
    "model_wv = model.wv\n",
    "model_wv.save_word2vec_format('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/word2vec_semeval.gensim')\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/word2vec_semeval.gensim', binary=False)\n",
    "word_vectors.save('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/word2vec_semeval.gensim', pickle_protocol=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "laptop_model = gensim.models.Word2Vec(\n",
    "    window=2,\n",
    "    min_count=5,\n",
    "#     sample=6e-5, \n",
    "    alpha=0.03, \n",
    "    min_alpha=0.0007, \n",
    "    workers=cores-1,\n",
    "    epochs=50\n",
    ")\n",
    "laptop_model.build_vocab(gensim_laptop, progress_per=10)\n",
    "total_examples = laptop_model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_model.build_vocab([list(vectors.key_to_index.keys())], update=True)\n",
    "# train on your data\n",
    "laptop_model.train(gensim_data, total_examples=total_examples, epochs=laptop_model.epochs)\n",
    "model_wv = laptop_model.wv\n",
    "model_wv.save_word2vec_format('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/word2vec_laptop.gensim')\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/word2vec_laptop.gensim', binary=False)\n",
    "word_vectors.save('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/word2vec_laptop.gensim', pickle_protocol=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "restaurant_model = gensim.models.Word2Vec(\n",
    "    window=2,\n",
    "    min_count=5,\n",
    "#     sample=6e-5, \n",
    "    alpha=0.03, \n",
    "    min_alpha=0.0007, \n",
    "    workers=cores-1,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "restaurant_model.build_vocab(gensim_restaurant, progress_per=10)\n",
    "total_examples = restaurant_model.corpus_count\n",
    "restaurant_model.build_vocab([list(vectors.key_to_index.keys())], update=True)\n",
    "# train on your data\n",
    "restaurant_model.train(gensim_data, total_examples=total_examples, epochs=restaurant_model.epochs)\n",
    "model_wv = restaurant_model.wv\n",
    "model_wv.save_word2vec_format('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/word2vec_restaurant.gensim')\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/word2vec_restaurant.gensim', binary=False)\n",
    "word_vectors.save('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/word2vec_restaurant.gensim', pickle_protocol=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train FastText"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on SemEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.test.utils import datapath\n",
    "model = gensim.models.fasttext.load_facebook_model(datapath('E:/UQ/REIT4882/unsupervised-absa/models/cc.en.300.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751075, 4082300)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_vocab(gensim_data, update=True)\n",
    "model.train(corpus_iterable=gensim_data, total_examples=len(gensim_data), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/fast_text_semeval.gensim')\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/fast_text_semeval.gensim', binary=False)\n",
    "word_vectors.save('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/fast_text_semeval.gensim', pickle_protocol=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on Laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.test.utils import datapath\n",
    "laptop_model = gensim.models.fasttext.load_facebook_model(datapath('E:/UQ/REIT4882/unsupervised-absa/models/cc.en.300.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351171, 2111450)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_model.build_vocab(gensim_laptop, update=True)\n",
    "laptop_model.train(corpus_iterable=gensim_laptop, total_examples=len(gensim_laptop), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_model.wv.save_word2vec_format('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/fast_text_laptop.gensim')\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/fast_text_laptop.gensim', binary=False)\n",
    "word_vectors.save('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/fast_text_laptop.gensim', pickle_protocol=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.test.utils import datapath\n",
    "restaurant_model = gensim.models.fasttext.load_facebook_model(datapath('E:/UQ/REIT4882/unsupervised-absa/models/cc.en.300.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364849, 1970850)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_model.build_vocab(gensim_restaurant, update=True)\n",
    "restaurant_model.train(corpus_iterable=gensim_restaurant, total_examples=len(gensim_restaurant), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_model.wv.save_word2vec_format('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/fast_text_restaurant.gensim')\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/fast_text_restaurant.gensim', binary=False)\n",
    "word_vectors.save('E:/UQ/REIT4882/unsupervised-absa/models/further_pretrain/fast_text_restaurant.gensim', pickle_protocol=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17428\\3530027275.py:8: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  _ = glove2word2vec(glove_file, tmp_file)\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m glove_file \u001b[39m=\u001b[39m datapath(\u001b[39m'\u001b[39m\u001b[39mE:/UQ/REIT4882/unsupervised-absa/examples/glove.gensim\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m tmp_file \u001b[39m=\u001b[39m get_tmpfile(\u001b[39m\"\u001b[39m\u001b[39mtest_word2vec.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m _ \u001b[39m=\u001b[39m glove2word2vec(glove_file, tmp_file)\n\u001b[0;32m     10\u001b[0m glove_vectors \u001b[39m=\u001b[39m KeyedVectors\u001b[39m.\u001b[39mload_word2vec_format(tmp_file)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch-flair\\lib\\site-packages\\gensim\\utils.py:1522\u001b[0m, in \u001b[0;36mdeprecated.<locals>.decorator.<locals>.new_func1\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m   1516\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_func1\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1517\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1518\u001b[0m         fmt\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, reason\u001b[39m=\u001b[39mreason),\n\u001b[0;32m   1519\u001b[0m         category\u001b[39m=\u001b[39m\u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1520\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m   1521\u001b[0m     )\n\u001b[1;32m-> 1522\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch-flair\\lib\\site-packages\\gensim\\scripts\\glove2word2vec.py:109\u001b[0m, in \u001b[0;36mglove2word2vec\u001b[1;34m(glove_input_file, word2vec_output_file)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39m@deprecated\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mKeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mglove2word2vec\u001b[39m(glove_input_file, word2vec_output_file):\n\u001b[0;32m     94\u001b[0m     \u001b[39m\"\"\"Convert `glove_input_file` in GloVe format to word2vec format and write it to `word2vec_output_file`.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[0;32m     96\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \n\u001b[0;32m    108\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     glovekv \u001b[39m=\u001b[39m KeyedVectors\u001b[39m.\u001b[39;49mload_word2vec_format(glove_input_file, binary\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, no_header\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    111\u001b[0m     num_lines, num_dims \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(glovekv), glovekv\u001b[39m.\u001b[39mvector_size\n\u001b[0;32m    112\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mconverting \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m vectors from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, num_lines, glove_input_file, word2vec_output_file)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch-flair\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[39mcls\u001b[39m, fname, fvocab\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m, unicode_errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, datatype\u001b[39m=\u001b[39mREAL, no_header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m     \u001b[39m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[39m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[0;32m   1720\u001b[0m         \u001b[39mcls\u001b[39;49m, fname, fvocab\u001b[39m=\u001b[39;49mfvocab, binary\u001b[39m=\u001b[39;49mbinary, encoding\u001b[39m=\u001b[39;49mencoding, unicode_errors\u001b[39m=\u001b[39;49municode_errors,\n\u001b[0;32m   1721\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit, datatype\u001b[39m=\u001b[39;49mdatatype, no_header\u001b[39m=\u001b[39;49mno_header,\n\u001b[0;32m   1722\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch-flair\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2054\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2052\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mno_header only available for text-format files\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2053\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# text\u001b[39;00m\n\u001b[1;32m-> 2054\u001b[0m     vocab_size, vector_size \u001b[39m=\u001b[39m _word2vec_detect_sizes_text(fin, limit, datatype, unicode_errors, encoding)\n\u001b[0;32m   2055\u001b[0m fin\u001b[39m.\u001b[39mclose()\n\u001b[0;32m   2056\u001b[0m fin \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mopen(fname, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch-flair\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1992\u001b[0m, in \u001b[0;36m_word2vec_detect_sizes_text\u001b[1;34m(fin, limit, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[0;32m   1990\u001b[0m     \u001b[39mif\u001b[39;00m vector_size:\n\u001b[0;32m   1991\u001b[0m         \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't bother parsing lines past the 1st\u001b[39;00m\n\u001b[1;32m-> 1992\u001b[0m     word, weights \u001b[39m=\u001b[39m _word2vec_line_to_vector(line, datatype, unicode_errors, encoding)\n\u001b[0;32m   1993\u001b[0m     vector_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(weights)\n\u001b[0;32m   1994\u001b[0m \u001b[39mreturn\u001b[39;00m vocab_size, vector_size\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch-flair\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1979\u001b[0m, in \u001b[0;36m_word2vec_line_to_vector\u001b[1;34m(line, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[0;32m   1978\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_word2vec_line_to_vector\u001b[39m(line, datatype, unicode_errors, encoding):\n\u001b[1;32m-> 1979\u001b[0m     parts \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mto_unicode(line\u001b[39m.\u001b[39;49mrstrip(), encoding\u001b[39m=\u001b[39;49mencoding, errors\u001b[39m=\u001b[39;49municode_errors)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1980\u001b[0m     word, weights \u001b[39m=\u001b[39m parts[\u001b[39m0\u001b[39m], [datatype(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m parts[\u001b[39m1\u001b[39m:]]\n\u001b[0;32m   1981\u001b[0m     \u001b[39mreturn\u001b[39;00m word, weights\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\torch-flair\\lib\\site-packages\\gensim\\utils.py:365\u001b[0m, in \u001b[0;36many2unicode\u001b[1;34m(text, encoding, errors)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    364\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n\u001b[1;32m--> 365\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39;49m(text, encoding, errors\u001b[39m=\u001b[39;49merrors)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "glove_file = datapath('E:/UQ/REIT4882/unsupervised-absa/examples/glove.gensim')\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "glove_vectors = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_data = list(preprocessed_df['text'].apply(gensim.utils.simple_preprocess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=2,\n",
    "    min_count=5,\n",
    "#     sample=6e-5, \n",
    "    alpha=0.03, \n",
    "    min_alpha=0.0007, \n",
    "    negative=0,\n",
    "    workers=cores-1\n",
    ")\n",
    "model.build_vocab(gensim_data, progress_per=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab([list(glove_vectors.vocab.keys())], update=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-flair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
