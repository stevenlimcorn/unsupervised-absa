{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.mnli import MnliPipeline\n",
    "model = MnliPipeline('microsoft/deberta-large-mnli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data_2016/pos tag/laptop_pos_tag.json') as f:\n",
    "    pos_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos_tag_df = pd.DataFrame.from_dict(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1735it [00:00, 19261.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# expanding the df to sentence to 1 pos tag df\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "new_df = {'text': [], 'sid': [], 'aspectLabel': [], 'term ground truth': [], 'category ground truth': []}\n",
    "for index, row in tqdm(pos_tag_df.iterrows()):\n",
    "    if len(row['pos_tag']) != 0:\n",
    "        text = row['text']\n",
    "        sid = row['sentenceId']\n",
    "        term_ground_truth = row['term ground truth']\n",
    "        category_ground_truth = row['term ground truth']\n",
    "        for aspect in row['pos_tag']:\n",
    "            new_df['aspectLabel'].append(aspect['word'])\n",
    "            new_df['text'].append(text)\n",
    "            new_df['sid'].append(sid)\n",
    "            new_df['term ground truth'].append(term_ground_truth)\n",
    "            new_df['category ground truth'].append(category_ground_truth)\n",
    "\n",
    "mnli_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-23 20:14:27.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mPreprocessing dataset with length: 3972\u001b[0m\n",
      "\u001b[32m2023-04-23 20:14:27.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mExtracting polarity with model: microsoft/deberta-large-mnli\u001b[0m\n",
      " 31%|███       | 1238/3972 [14:19<27:51,  1.64it/s] "
     ]
    }
   ],
   "source": [
    "dataset = model.extract_polarity(mnli_df, 'text', 'aspectLabel', device='cuda', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ce6aae5c984e23bb2c259aac6eded0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk('../data_2016/mnli/laptop_aspect_term')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words Count > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data_2016/pos tag/laptop_pos_tag_low_counts.json') as f:\n",
    "    pos_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos_tag_df = pd.DataFrame.from_dict(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6055it [00:00, 21227.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# expanding the df to sentence to 1 pos tag df\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "new_df = {'text': [], 'sid': [], 'aspectLabel': [], 'term ground truth': [], 'category ground truth': []}\n",
    "for index, row in tqdm(pos_tag_df.iterrows()):\n",
    "    if len(row['pos_tag']) != 0:\n",
    "        text = row['text']\n",
    "        sid = row['sentenceId']\n",
    "        term_ground_truth = row['term ground truth']\n",
    "        category_ground_truth = row['term ground truth']\n",
    "        for aspect in row['pos_tag']:\n",
    "            new_df['aspectLabel'].append(aspect['word'])\n",
    "            new_df['text'].append(text)\n",
    "            new_df['sid'].append(sid)\n",
    "            new_df['term ground truth'].append(term_ground_truth)\n",
    "            new_df['category ground truth'].append(category_ground_truth)\n",
    "\n",
    "mnli_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-14 00:19:59.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mPreprocessing dataset with length: 11666\u001b[0m\n",
      "\u001b[32m2023-04-14 00:19:59.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mExtracting polarity with model: microsoft/deberta-large-mnli\u001b[0m\n",
      "  4%|▍         | 513/11666 [07:05<2:28:46,  1.25it/s]"
     ]
    }
   ],
   "source": [
    "low_counts_dataset = model.extract_polarity(mnli_df, 'text', 'aspectLabel', device='cuda', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_counts_dataset.save_to_disk('../data_2016/mnli/laptop_aspect_term_low_counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data_2015/pos tag/restaurant_pos_tag.json') as f:\n",
    "    pos_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos_tag_df = pd.DataFrame.from_dict(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1739it [00:00, 20441.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# expanding the df to sentence to 1 pos tag df\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "new_df = {'text': [], 'sid': [], 'aspectLabel': [], 'term ground truth': [], 'category ground truth': []}\n",
    "for index, row in tqdm(pos_tag_df.iterrows()):\n",
    "    if len(row['pos_tag']) != 0:\n",
    "        text = row['text']\n",
    "        sid = row['sentenceId']\n",
    "        term_ground_truth = row['term ground truth']\n",
    "        category_ground_truth = row['term ground truth']\n",
    "        for aspect in row['pos_tag']:\n",
    "            new_df['aspectLabel'].append(aspect['word'])\n",
    "            new_df['text'].append(text)\n",
    "            new_df['sid'].append(sid)\n",
    "            new_df['term ground truth'].append(term_ground_truth)\n",
    "            new_df['category ground truth'].append(category_ground_truth)\n",
    "\n",
    "mnli_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-23 19:30:58.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mPreprocessing dataset with length: 4057\u001b[0m\n",
      "\u001b[32m2023-04-23 19:30:58.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mExtracting polarity with model: microsoft/deberta-large-mnli\u001b[0m\n",
      "  3%|▎         | 120/4057 [01:18<43:10,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = model.extract_polarity(mnli_df, 'text', 'aspectLabel', device='cuda', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ce6aae5c984e23bb2c259aac6eded0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk('../data_2016/mnli/restaurant_aspect_term')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words Count > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data_2016/pos tag/restaurant_pos_tag_low_counts.json') as f:\n",
    "    pos_tags = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos_tag_df = pd.DataFrame.from_dict(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6055it [00:00, 21227.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# expanding the df to sentence to 1 pos tag df\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "new_df = {'text': [], 'sid': [], 'aspectLabel': [], 'term ground truth': [], 'category ground truth': []}\n",
    "for index, row in tqdm(pos_tag_df.iterrows()):\n",
    "    if len(row['pos_tag']) != 0:\n",
    "        text = row['text']\n",
    "        sid = row['sentenceId']\n",
    "        term_ground_truth = row['term ground truth']\n",
    "        category_ground_truth = row['term ground truth']\n",
    "        for aspect in row['pos_tag']:\n",
    "            new_df['aspectLabel'].append(aspect['word'])\n",
    "            new_df['text'].append(text)\n",
    "            new_df['sid'].append(sid)\n",
    "            new_df['term ground truth'].append(term_ground_truth)\n",
    "            new_df['category ground truth'].append(category_ground_truth)\n",
    "\n",
    "mnli_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-14 00:19:59.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mPreprocessing dataset with length: 11666\u001b[0m\n",
      "\u001b[32m2023-04-14 00:19:59.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.mnli\u001b[0m:\u001b[36mextract_polarity\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mExtracting polarity with model: microsoft/deberta-large-mnli\u001b[0m\n",
      "  4%|▍         | 513/11666 [07:05<2:28:46,  1.25it/s]"
     ]
    }
   ],
   "source": [
    "low_counts_dataset = model.extract_polarity(mnli_df, 'text', 'aspectLabel', device='cuda', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_counts_dataset.save_to_disk('../data_2016/mnli/restaurant_aspect_term_low_counts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
