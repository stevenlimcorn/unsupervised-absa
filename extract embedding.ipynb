{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement unsupervised_absa (from versions: none)\n",
      "ERROR: No matching distribution found for unsupervised_absa\n"
     ]
    }
   ],
   "source": [
    "%pip install unsupervised_absa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is used to extract the word embeddings of each nouns that are tagged from pos tagging process. These terms will be clustered to get the specific domain they are in."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short words removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6055/6055 [00:00<00:00, 1512777.62it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "with open('data/pos tag/semeval_pos_tag_remove_short_words.json') as f:\n",
    "    pos_tags = json.load(f)\n",
    "\n",
    "list_of_words = []\n",
    "for row in tqdm(pos_tags):\n",
    "    for pos_data in row['pos_tag']:\n",
    "        list_of_words.append(pos_data['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of words, remove all the \n",
    "# convert words to lower case\n",
    "list_of_words = list(set(map(lambda x: x.lower(), list_of_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\torch-flair\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datasets import load_from_disk\n",
    "from flair.data import Sentence\n",
    "preprocessed_dataset = load_from_disk('data/preprocessed_data')\n",
    "# get the sentences\n",
    "preprocessed_df = preprocessed_dataset.to_pandas()\n",
    "preprocessed_df = preprocessed_df.drop_duplicates(subset=['text'])\n",
    "tf_idf_data = [Sentence(text) for text in preprocessed_df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-16 00:05:34.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "tfidf_embedding = ExtractEmbedding(ModelType.TFIDF, tf_idf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3906/3906 [00:03<00:00, 1259.53it/s]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_embedding_data = tfidf_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_tfidf_embedding.npy', tf_idf_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-15 14:01:18.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "glove_embedding = ExtractEmbedding(ModelType.WORD, 'glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3906/3906 [00:00<00:00, 5615.31it/s]\n"
     ]
    }
   ],
   "source": [
    "glove_embedding_data = glove_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_glove_embedding.npy', glove_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-15 14:01:41.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "fast_text_embedding = ExtractEmbedding(ModelType.WORD, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3906/3906 [00:00<00:00, 5726.55it/s]\n"
     ]
    }
   ],
   "source": [
    "fast_text_embedding_data = fast_text_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_fast_text_embedding.npy', fast_text_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is not in flair, what we can do is convert from gensim to flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Word2Vec pretrained on google news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "model_path = gensim.downloader.load('word2vec-google-news-300', return_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model to keyedvector and save it as keyedvector\n",
    "vectors = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "vectors.save('models/word2vec-google.gensim', pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-16 00:09:25.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "word2vec_embedding = ExtractEmbedding(ModelType.WORD, 'models/word2vec-google.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3906/3906 [00:00<00:00, 5439.23it/s]\n"
     ]
    }
   ],
   "source": [
    "word2vec_embedding_data = word2vec_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_word2vec_embedding.npy', word2vec_embedding_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a1c668458743d8a27de1ec2cb3fc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-15 14:13:03.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "bert_embedding = ExtractEmbedding(ModelType.TRANSFORMER_WORD, 'bert-large-uncased', device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3906/3906 [05:52<00:00, 11.09it/s]\n"
     ]
    }
   ],
   "source": [
    "bert_embedding_data = bert_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_bert_embedding.npy', bert_embedding_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bart-Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ad181f69c94b87b354cca3a74fa224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da361ae5c1984b4c9fbf52672b7eb890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc101a3cbdf9479387d8656e089a446f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db5258990bd491897b294f1d3f7acad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c6c287e5bd4c588b6e1399d31ee4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a86d17a28d4e2d82fbfa03e2458f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-15 14:21:54.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "bart_embedding = ExtractEmbedding(ModelType.TRANSFORMER_WORD, 'facebook/bart-large', device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3906/3906 [06:40<00:00,  9.75it/s]\n"
     ]
    }
   ],
   "source": [
    "bart_embedding_data = bart_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_bart_embedding.npy', bart_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deberta-v3-Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-15 14:29:55.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "deberta_embedding = ExtractEmbedding(ModelType.TRANSFORMER_WORD, 'microsoft/deberta-v3-large', device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 227/3906 [02:21<38:21,  1.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m deberta_embedding_data \u001b[39m=\u001b[39m deberta_embedding\u001b[39m.\u001b[39;49mextract(list_of_words)\n",
      "File \u001b[1;32me:\\UQ\\REIT4882\\unsupervised-absa\\unsupervised_absa\\embedding.py:86\u001b[0m, in \u001b[0;36mExtractEmbedding.extract\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m tqdm(texts):\n\u001b[0;32m     85\u001b[0m     sentence \u001b[39m=\u001b[39m Sentence(text)\n\u001b[1;32m---> 86\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49membed(sentence)\n\u001b[0;32m     87\u001b[0m     \u001b[39m# extract the embeddings for the text\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, StackedEmbeddings):\n\u001b[0;32m     89\u001b[0m         \u001b[39m# extract embeddings for all the models given\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\flair\\embeddings\\base.py:49\u001b[0m, in \u001b[0;36mEmbeddings.embed\u001b[1;34m(self, data_points)\u001b[0m\n\u001b[0;32m     46\u001b[0m     data_points \u001b[39m=\u001b[39m [data_points]\n\u001b[0;32m     48\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_everything_embedded(data_points):\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_embeddings_internal(data_points)\n\u001b[0;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m data_points\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\flair\\embeddings\\transformer.py:662\u001b[0m, in \u001b[0;36mTransformerBaseEmbeddings._add_embeddings_internal\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m    660\u001b[0m gradient_context \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39menable_grad() \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfine_tune \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining) \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad()\n\u001b[0;32m    661\u001b[0m \u001b[39mwith\u001b[39;00m gradient_context:\n\u001b[1;32m--> 662\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_tensors(tensors)\n\u001b[0;32m    664\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocument_embedding:\n\u001b[0;32m    665\u001b[0m     document_embedding \u001b[39m=\u001b[39m embeddings[\u001b[39m\"\u001b[39m\u001b[39mdocument_embeddings\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\flair\\embeddings\\transformer.py:1319\u001b[0m, in \u001b[0;36mTransformerEmbeddings._forward_tensors\u001b[1;34m(self, tensors)\u001b[0m\n\u001b[0;32m   1318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_tensors\u001b[39m(\u001b[39mself\u001b[39m, tensors) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m-> 1319\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtensors)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\flair\\embeddings\\transformer.py:1223\u001b[0m, in \u001b[0;36mTransformerEmbeddings.forward\u001b[1;34m(self, input_ids, sub_token_lengths, token_lengths, attention_mask, overflow_to_sample_mapping, word_ids, langs, bbox, pixel_values)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[39mif\u001b[39;00m pixel_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1222\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mpixel_values\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pixel_values\n\u001b[1;32m-> 1223\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m   1224\u001b[0m \u001b[39m# make the tuple a tensor; makes working with it easier.\u001b[39;00m\n\u001b[0;32m   1225\u001b[0m hidden_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:1083\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1073\u001b[0m     token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m   1075\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1076\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1077\u001b[0m     token_type_ids\u001b[39m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1080\u001b[0m     inputs_embeds\u001b[39m=\u001b[39minputs_embeds,\n\u001b[0;32m   1081\u001b[0m )\n\u001b[1;32m-> 1083\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1084\u001b[0m     embedding_output,\n\u001b[0;32m   1085\u001b[0m     attention_mask,\n\u001b[0;32m   1086\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1087\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1088\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1089\u001b[0m )\n\u001b[0;32m   1090\u001b[0m encoded_layers \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m1\u001b[39m]\n\u001b[0;32m   1092\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz_steps \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:521\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[1;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[0;32m    512\u001b[0m     output_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    513\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    514\u001b[0m         next_kv,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    518\u001b[0m         rel_embeddings,\n\u001b[0;32m    519\u001b[0m     )\n\u001b[0;32m    520\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     output_states \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    522\u001b[0m         next_kv,\n\u001b[0;32m    523\u001b[0m         attention_mask,\n\u001b[0;32m    524\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[0;32m    525\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[0;32m    526\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[0;32m    527\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    528\u001b[0m     )\n\u001b[0;32m    530\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[0;32m    531\u001b[0m     output_states, att_m \u001b[39m=\u001b[39m output_states\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:362\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[1;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    354\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    355\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    360\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    361\u001b[0m ):\n\u001b[1;32m--> 362\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    363\u001b[0m         hidden_states,\n\u001b[0;32m    364\u001b[0m         attention_mask,\n\u001b[0;32m    365\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    366\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[0;32m    367\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[0;32m    368\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[0;32m    370\u001b[0m     \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[0;32m    371\u001b[0m         attention_output, att_matrix \u001b[39m=\u001b[39m attention_output\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:293\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    285\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    286\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m     rel_embeddings\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    292\u001b[0m ):\n\u001b[1;32m--> 293\u001b[0m     self_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[0;32m    294\u001b[0m         hidden_states,\n\u001b[0;32m    295\u001b[0m         attention_mask,\n\u001b[0;32m    296\u001b[0m         output_attentions,\n\u001b[0;32m    297\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[0;32m    298\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[0;32m    299\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[0;32m    300\u001b[0m     )\n\u001b[0;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[0;32m    302\u001b[0m         self_output, att_matrix \u001b[39m=\u001b[39m self_output\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:728\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelative_attention:\n\u001b[0;32m    727\u001b[0m     rel_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_dropout(rel_embeddings)\n\u001b[1;32m--> 728\u001b[0m     rel_att \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdisentangled_attention_bias(\n\u001b[0;32m    729\u001b[0m         query_layer, key_layer, relative_pos, rel_embeddings, scale_factor\n\u001b[0;32m    730\u001b[0m     )\n\u001b[0;32m    732\u001b[0m \u001b[39mif\u001b[39;00m rel_att \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    733\u001b[0m     attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m+\u001b[39m rel_att\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:783\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.disentangled_attention_bias\u001b[1;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_att_key:\n\u001b[0;32m    780\u001b[0m     pos_query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\n\u001b[0;32m    781\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_proj(rel_embeddings), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_attention_heads\n\u001b[0;32m    782\u001b[0m     )\u001b[39m.\u001b[39mrepeat(query_layer\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_attention_heads, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m--> 783\u001b[0m     pos_key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_proj(rel_embeddings), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_attention_heads)\u001b[39m.\u001b[39mrepeat(\n\u001b[0;32m    784\u001b[0m         query_layer\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_attention_heads, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m\n\u001b[0;32m    785\u001b[0m     )\n\u001b[0;32m    786\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mc2p\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_att_type:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deberta_embedding_data = deberta_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_deberta_embedding.npy', deberta_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sup-promcse-roberta-large word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 19:50:35.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "promcse_embedding = ExtractEmbedding(ModelType.TRANSFORMER_DOC, 'YuxinJiang/sup-promcse-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [04:46<00:00,  4.86it/s]\n"
     ]
    }
   ],
   "source": [
    "promcse_embedding_data = promcse_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/promcse_word_embedding.npy', promcse_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sup-simcse-roberta-large word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 19:55:30.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "simcse_embedding = ExtractEmbedding(ModelType.TRANSFORMER_DOC, 'princeton-nlp/sup-simcse-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [04:36<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "simcse_embedding_data = simcse_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/simcse_word_embedding.npy', simcse_embedding_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MiniLM-L12-H384-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 20:00:09.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "mini_lm = ExtractEmbedding(ModelType.TRANSFORMER_DOC, 'microsoft/MiniLM-L12-H384-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [00:22<00:00, 61.28it/s]\n"
     ]
    }
   ],
   "source": [
    "mini_lm_embedding_data = mini_lm.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/all_MiniLM_L6_v2_word_embedding.npy', mini_lm_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacked embedding of the embedding models [bert, glove, FastText, Word2Vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "\u001b[32m2023-04-13 19:25:37.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "stacked_embedding = ExtractEmbedding([ModelType.TRANSFORMER_WORD, ModelType.TRANSFORMER_WORD, ModelType.WORD, ModelType.WORD, ModelType.WORD], ['microsoft/deberta-v3-large', 'bert-base-uncased', 'glove', 'en', 'models/word2vec-google.gensim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [24:47<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "stacked_embedding_data = stacked_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_stacked_embedding.npy', stacked_embedding_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Frequency (words with count 1) Words Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6055/6055 [00:00<00:00, 1728594.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "with open('data/pos tag/semeval_pos_tag_remove_short_words_and_low_counts.json') as f:\n",
    "    pos_tags = json.load(f)\n",
    "\n",
    "list_of_words = []\n",
    "for row in tqdm(pos_tags):\n",
    "    for pos_data in row['pos_tag']:\n",
    "        list_of_words.append(pos_data['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of words, remove all the \n",
    "# convert words to lower case\n",
    "list_of_words = list(set(map(lambda x: x.lower(), list_of_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1393"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datasets import load_from_disk\n",
    "from flair.data import Sentence\n",
    "preprocessed_dataset = load_from_disk('data/preprocessed_data')\n",
    "# get the sentences\n",
    "preprocessed_df = preprocessed_dataset.to_pandas()\n",
    "preprocessed_df = preprocessed_df.drop_duplicates(subset=['text'])\n",
    "tf_idf_data = [Sentence(text) for text in preprocessed_df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-16 00:06:01.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "tfidf_embedding = ExtractEmbedding(ModelType.TFIDF, tf_idf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [00:01<00:00, 1228.42it/s]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_embedding_data = tfidf_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_tfidf_embedding_word_count.npy', tf_idf_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 20:26:48.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "glove_embedding = ExtractEmbedding(ModelType.WORD, 'glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [00:00<00:00, 4154.65it/s]\n"
     ]
    }
   ],
   "source": [
    "glove_embedding_data = glove_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_glove_embedding_word_count.npy', glove_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 20:27:07.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "fast_text_embedding = ExtractEmbedding(ModelType.WORD, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [00:00<00:00, 3428.09it/s]\n"
     ]
    }
   ],
   "source": [
    "fast_text_embedding_data = fast_text_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_fast_text_embedding_word_count.npy', fast_text_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is not in flair, what we can do is convert from gensim to flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Word2Vec pretrained on google news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "model_path = gensim.downloader.load('word2vec-google-news-300', return_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model to keyedvector and save it as keyedvector\n",
    "vectors = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "vectors.save('models/word2vec-google.gensim', pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-16 00:10:41.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "word2vec_embedding = ExtractEmbedding(ModelType.WORD, 'models/word2vec-google.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [00:00<00:00, 3532.48it/s]\n"
     ]
    }
   ],
   "source": [
    "word2vec_embedding_data = word2vec_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_word2vec_embedding_word_count.npy', word2vec_embedding_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 16.0kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 571/571 [00:00<00:00, 170kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 595kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.00MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.34G/1.34G [01:21<00:00, 16.6MB/s]\n",
      "\u001b[32m2023-04-14 16:27:37.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "bert_embedding = ExtractEmbedding(ModelType.TRANSFORMER_WORD, 'bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [03:40<00:00,  6.31it/s]\n"
     ]
    }
   ],
   "source": [
    "bert_embedding_data = bert_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_bert_embedding_word_count.npy', bert_embedding_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bart-Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-14 16:19:38.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "bart_embedding = ExtractEmbedding(ModelType.TRANSFORMER_WORD, 'facebook/bart-large', device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [03:23<00:00,  6.86it/s]\n"
     ]
    }
   ],
   "source": [
    "bart_embedding_data = bart_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_bart_embedding_word_count.npy', bart_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deberta-v3-Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "deberta_embedding = ExtractEmbedding(ModelType.TRANSFORMER_WORD, 'microsoft/deberta-v3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [24:32<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "deberta_embedding_data = deberta_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_deberta_embedding_word_count.npy', deberta_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sup-promcse-roberta-large word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 21:10:01.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "promcse_embedding = ExtractEmbedding(ModelType.TRANSFORMER_DOC, 'YuxinJiang/sup-promcse-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [04:10<00:00,  5.57it/s]\n"
     ]
    }
   ],
   "source": [
    "promcse_embedding_data = promcse_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/promcse_word_embedding_word_count.npy', promcse_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sup-simcse-roberta-large word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 21:14:18.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "simcse_embedding = ExtractEmbedding(ModelType.TRANSFORMER_DOC, 'princeton-nlp/sup-simcse-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [05:11<00:00,  4.48it/s]\n"
     ]
    }
   ],
   "source": [
    "simcse_embedding_data = simcse_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/simcse_word_embedding_word_count.npy', simcse_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 21:19:31.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "mini_lm_embedding = ExtractEmbedding(ModelType.TRANSFORMER_DOC, 'sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [00:35<00:00, 39.47it/s]\n"
     ]
    }
   ],
   "source": [
    "mini_lm_embedding_data = mini_lm_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/all_MiniLM_L6_v2_word_embedding_word_count.npy', mini_lm_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacked embedding of the embedding models [bert, glove, FastText, Word2Vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\absa\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "\u001b[32m2023-04-13 20:31:47.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "stacked_embedding = ExtractEmbedding([ModelType.TRANSFORMER_WORD, ModelType.TRANSFORMER_WORD, ModelType.WORD, ModelType.WORD, ModelType.WORD], ['microsoft/deberta-v3-large', 'bert-base-uncased', 'glove', 'en', 'models/word2vec-google.gensim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [24:37<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "stacked_embedding_data = stacked_embedding.extract(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/word embedding data/sem_eval_stacked_embedding_word_count.npy', stacked_embedding_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "preprocessed_dataset = load_from_disk('data/preprocessed data')\n",
    "# get the sentences\n",
    "preprocessed_df = preprocessed_dataset.to_pandas()\n",
    "preprocessed_df = preprocessed_df.drop_duplicates(subset=['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sup-promcse-roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-12 13:28:07.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "promcse_embedding = ExtractEmbedding(ModelType.TRANSFORMER_DOC, 'YuxinJiang/sup-promcse-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6055/6055 [17:53<00:00,  5.64it/s]\n"
     ]
    }
   ],
   "source": [
    "promcse_embedding_data = promcse_embedding.extract(preprocessed_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/sentence embedding data/promcse_embedding.npy', promcse_embedding_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sup-simcse-roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-12 13:46:04.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "simcse_embedding = ExtractEmbedding(ModelType.TRANSFORMER_DOC, 'princeton-nlp/sup-simcse-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6055/6055 [18:21<00:00,  5.50it/s]  \n"
     ]
    }
   ],
   "source": [
    "simcse_embedding_data = simcse_embedding.extract(preprocessed_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/sentence embedding data/simcse_embedding.npy', simcse_embedding_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MiniLM-L12-H384-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-12 14:04:28.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "all_MiniLM_L6_v2_embedding = ExtractEmbedding(ModelType.TRANSFORMER_DOC, 'sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6055/6055 [01:10<00:00, 86.18it/s]\n"
     ]
    }
   ],
   "source": [
    "all_MiniLM_L6_v2_embedding_data = all_MiniLM_L6_v2_embedding.extract(preprocessed_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/sentence embedding data/all_MiniLM_L6_v2_embedding.npy', all_MiniLM_L6_v2_embedding_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacked Sentence Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacked embedding of the embedding models [sup-promcse-roberta-large, princeton-nlp/sup-simcse-roberta-large, sentence-transformers/all-MiniLM-L6-v2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-12 14:05:47.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36munsupervised_absa.embedding\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTagger model instantiated with device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from unsupervised_absa.embedding import ExtractEmbedding, ModelType\n",
    "stacked_sentence_embedding = ExtractEmbedding([ModelType.TRANSFORMER_DOC, ModelType.TRANSFORMER_DOC, ModelType.TRANSFORMER_DOC], ['YuxinJiang/sup-promcse-roberta-large', 'princeton-nlp/sup-simcse-roberta-large', 'sentence-transformers/all-MiniLM-L6-v2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6055/6055 [37:26<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "stacked_sentence_embedding_data = stacked_sentence_embedding.extract(preprocessed_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('data/sentence embedding data/stacked_sentence_embedding.npy', stacked_sentence_embedding_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
